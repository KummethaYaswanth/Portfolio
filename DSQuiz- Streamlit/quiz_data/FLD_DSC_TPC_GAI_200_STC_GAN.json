{
  "fieldId": "FLD_DSC",
  "fieldName": "Data Science",
  "topicId": "TPC_GAI",
  "topicName": "Generative AI",
  "subtopicId": "STC_GAN",
  "subtopicName": "Generative Adversarial Networks",
  "str": 0.200,
  "description": "Comprehensive study of Generative Adversarial Networks, covering fundamental concepts, architectures, training dynamics, and advanced variants",
  "questions": [
    {
      "id": "GAN_001",
      "question": "Who introduced the concept of Generative Adversarial Networks (GANs)?",
      "options": [
        "Ian Goodfellow",
        "Geoffrey Hinton",
        "Yann LeCun",
        "Yoshua Bengio"
      ],
      "correctOptionIndex": 0,
      "explanation": "Ian Goodfellow introduced GANs in his 2014 paper 'Generative Adversarial Nets', which became one of the most influential papers in deep learning.",
      "optionExplanations": [
        "Correct. Ian Goodfellow is the original inventor of GANs, proposing the concept in 2014.",
        "Incorrect. Geoffrey Hinton is a pioneer in deep learning but did not invent GANs.",
        "Incorrect. Yann LeCun is known for convolutional neural networks but not GANs.",
        "Incorrect. Yoshua Bengio contributed to deep learning foundations but did not create GANs."
      ],
      "difficulty": "EASY",
      "tags": [
        "history",
        "fundamentals",
        "Ian_Goodfellow"
      ]
    },
    {
      "id": "GAN_002",
      "question": "What are the two main components of a GAN architecture?",
      "options": [
        "Generator and Discriminator",
        "Encoder and Decoder",
        "Classifier and Regressor",
        "Compressor and Decompressor"
      ],
      "correctOptionIndex": 0,
      "explanation": "GANs consist of two neural networks: a Generator that creates fake data and a Discriminator that tries to distinguish between real and fake data.",
      "optionExplanations": [
        "Correct. The Generator creates synthetic data while the Discriminator evaluates its authenticity.",
        "Incorrect. Encoder-Decoder is the architecture used in autoencoders, not GANs.",
        "Incorrect. Classifier-Regressor refers to supervised learning tasks, not GAN components.",
        "Incorrect. Compressor-Decompressor is related to data compression, not GANs."
      ],
      "difficulty": "EASY",
      "tags": [
        "architecture",
        "components",
        "fundamentals"
      ]
    },
    {
      "id": "GAN_003",
      "question": "What is the primary goal of the Generator in a GAN?",
      "options": [
        "To classify real data accurately",
        "To generate synthetic data that fools the Discriminator",
        "To compress input data efficiently",
        "To reduce training time"
      ],
      "correctOptionIndex": 1,
      "explanation": "The Generator's objective is to create synthetic data so realistic that the Discriminator cannot distinguish it from real data.",
      "optionExplanations": [
        "Incorrect. Classification is the Discriminator's task, not the Generator's.",
        "Correct. The Generator aims to produce fake data indistinguishable from real data.",
        "Incorrect. Data compression is not the Generator's purpose in GANs.",
        "Incorrect. Reducing training time is not a primary goal of the Generator."
      ],
      "difficulty": "EASY",
      "tags": [
        "generator",
        "objectives",
        "fundamentals"
      ]
    },
    {
      "id": "GAN_004",
      "question": "What is the role of the Discriminator in a GAN?",
      "options": [
        "To generate new data samples",
        "To distinguish between real and fake data",
        "To optimize the loss function",
        "To preprocess input data"
      ],
      "correctOptionIndex": 1,
      "explanation": "The Discriminator acts as a binary classifier that tries to correctly identify whether input data is real or generated by the Generator.",
      "optionExplanations": [
        "Incorrect. Data generation is the Generator's responsibility.",
        "Correct. The Discriminator's job is to classify data as real or fake.",
        "Incorrect. Both networks optimize their respective loss functions, but this isn't the Discriminator's specific role.",
        "Incorrect. Data preprocessing is typically done before training, not by the Discriminator."
      ],
      "difficulty": "EASY",
      "tags": [
        "discriminator",
        "classification",
        "fundamentals"
      ]
    },
    {
      "id": "GAN_005",
      "question": "What type of learning paradigm do GANs represent?",
      "options": [
        "Supervised learning",
        "Reinforcement learning",
        "Unsupervised learning",
        "Semi-supervised learning"
      ],
      "correctOptionIndex": 2,
      "explanation": "GANs are unsupervised learning models because they learn to generate data without requiring labeled examples of the desired output.",
      "optionExplanations": [
        "Incorrect. Supervised learning requires labeled data, which GANs don't need.",
        "Incorrect. Reinforcement learning involves agents and rewards, not applicable to standard GANs.",
        "Correct. GANs learn patterns from data without explicit labels or supervision.",
        "Incorrect. Semi-supervised learning uses some labeled data, but GANs typically don't require any labels."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "learning_paradigm",
        "unsupervised",
        "fundamentals"
      ]
    },
    {
      "id": "GAN_006",
      "question": "What is the adversarial training process in GANs?",
      "options": [
        "Training both networks simultaneously to cooperate",
        "Training networks in competition where one tries to fool the other",
        "Training only the Generator while keeping Discriminator fixed",
        "Training networks on different datasets separately"
      ],
      "correctOptionIndex": 1,
      "explanation": "Adversarial training involves the Generator and Discriminator competing against each other in a minimax game, where each tries to optimize its own objective.",
      "optionExplanations": [
        "Incorrect. The networks compete rather than cooperate in adversarial training.",
        "Correct. It's a competitive process where the Generator tries to fool the Discriminator.",
        "Incorrect. Both networks are trained simultaneously, not just the Generator.",
        "Incorrect. Both networks are trained on related data, not separate datasets."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "adversarial_training",
        "competition",
        "minimax"
      ]
    },
    {
      "id": "GAN_007",
      "question": "What is the typical input to a GAN Generator?",
      "options": [
        "Real data samples",
        "Random noise vector",
        "Labeled training data",
        "Pre-trained features"
      ],
      "correctOptionIndex": 1,
      "explanation": "The Generator typically takes a random noise vector (usually from a normal or uniform distribution) and transforms it into synthetic data.",
      "optionExplanations": [
        "Incorrect. Real data samples are input to the Discriminator, not the Generator.",
        "Correct. Random noise serves as the seed for generating new data samples.",
        "Incorrect. GANs don't require labeled data as input to the Generator.",
        "Incorrect. The Generator creates features from noise, rather than using pre-trained ones."
      ],
      "difficulty": "EASY",
      "tags": [
        "generator",
        "input",
        "noise_vector"
      ]
    },
    {
      "id": "GAN_008",
      "question": "What is mode collapse in GANs?",
      "options": [
        "When the Generator produces diverse, high-quality samples",
        "When the Generator produces limited variety in outputs",
        "When the Discriminator becomes too powerful",
        "When training converges successfully"
      ],
      "correctOptionIndex": 1,
      "explanation": "Mode collapse occurs when the Generator learns to produce only a limited variety of samples, failing to capture the full diversity of the training data distribution.",
      "optionExplanations": [
        "Incorrect. This describes successful training, opposite of mode collapse.",
        "Correct. Mode collapse results in reduced diversity and repetitive outputs.",
        "Incorrect. While discriminator power can contribute to mode collapse, it's not the definition.",
        "Incorrect. Mode collapse represents a training failure, not successful convergence."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "mode_collapse",
        "training_issues",
        "diversity"
      ]
    },
    {
      "id": "GAN_009",
      "question": "What is the vanishing gradient problem in GANs?",
      "options": [
        "When gradients become too large during training",
        "When gradients become very small and impede learning",
        "When the loss function becomes unstable",
        "When the network architecture is too complex"
      ],
      "correctOptionIndex": 1,
      "explanation": "The vanishing gradient problem occurs when gradients become extremely small, making it difficult for the Generator to learn effectively from the Discriminator's feedback.",
      "optionExplanations": [
        "Incorrect. This describes exploding gradients, not vanishing gradients.",
        "Correct. Vanishing gradients slow or stop learning due to very small gradient values.",
        "Incorrect. Loss instability is a separate issue from vanishing gradients.",
        "Incorrect. Network complexity can contribute to gradient issues but isn't the definition."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "vanishing_gradients",
        "training_issues",
        "optimization"
      ]
    },
    {
      "id": "GAN_010",
      "question": "What does DCGAN stand for?",
      "options": [
        "Deep Convolutional Generative Adversarial Network",
        "Distributed Computing Generative Adversarial Network",
        "Dynamic Conditional Generative Adversarial Network",
        "Deep Contextual Generative Adversarial Network"
      ],
      "correctOptionIndex": 0,
      "explanation": "DCGAN stands for Deep Convolutional Generative Adversarial Network, which uses convolutional layers instead of fully connected layers.",
      "optionExplanations": [
        "Correct. DCGAN introduced convolutional architectures to GANs for better image generation.",
        "Incorrect. This is not related to the actual meaning of DCGAN.",
        "Incorrect. While conditional GANs exist, this is not what DCGAN stands for.",
        "Incorrect. This is not the correct expansion of the DCGAN acronym."
      ],
      "difficulty": "EASY",
      "tags": [
        "DCGAN",
        "convolutional",
        "variants"
      ]
    },
    {
      "id": "GAN_011",
      "question": "What architectural improvement did DCGAN introduce over vanilla GANs?",
      "options": [
        "Use of recurrent neural networks",
        "Use of convolutional and transpose convolutional layers",
        "Use of attention mechanisms",
        "Use of residual connections"
      ],
      "correctOptionIndex": 1,
      "explanation": "DCGAN replaced fully connected layers with convolutional layers in the Discriminator and transpose convolutional layers in the Generator, making it more suitable for image generation.",
      "optionExplanations": [
        "Incorrect. RNNs are not the key innovation in DCGANs.",
        "Correct. Convolutional architectures made GANs much more effective for image data.",
        "Incorrect. Attention mechanisms were introduced in later GAN variants.",
        "Incorrect. Residual connections were not the primary innovation in DCGANs."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "DCGAN",
        "architecture",
        "convolution"
      ]
    },
    {
      "id": "GAN_012",
      "question": "What is the main advantage of using transpose convolution in the DCGAN Generator?",
      "options": [
        "Reduces computational complexity",
        "Enables upsampling to generate larger images",
        "Improves training stability",
        "Reduces overfitting"
      ],
      "correctOptionIndex": 1,
      "explanation": "Transpose convolution (or deconvolution) allows the Generator to upsample from low-dimensional noise to high-dimensional images while maintaining spatial relationships.",
      "optionExplanations": [
        "Incorrect. Transpose convolution doesn't necessarily reduce computational complexity.",
        "Correct. Transpose convolution enables spatial upsampling for image generation.",
        "Incorrect. While it may help stability, upsampling is the primary functional advantage.",
        "Incorrect. Overfitting reduction is not the main purpose of transpose convolution."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "transpose_convolution",
        "upsampling",
        "DCGAN"
      ]
    },
    {
      "id": "GAN_013",
      "question": "What normalization technique is commonly used in DCGAN?",
      "options": [
        "Layer Normalization",
        "Instance Normalization",
        "Batch Normalization",
        "Group Normalization"
      ],
      "correctOptionIndex": 2,
      "explanation": "DCGAN commonly uses Batch Normalization to stabilize training and improve convergence, except in the Generator's output layer and Discriminator's input layer.",
      "optionExplanations": [
        "Incorrect. Layer normalization is less commonly used in DCGANs.",
        "Incorrect. Instance normalization is more common in style transfer tasks.",
        "Correct. Batch normalization is a key component of DCGAN architecture.",
        "Incorrect. Group normalization is a newer technique not originally used in DCGANs."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "batch_normalization",
        "DCGAN",
        "training_stability"
      ]
    },
    {
      "id": "GAN_014",
      "question": "What activation function is typically used in the DCGAN Generator's output layer?",
      "options": [
        "ReLU",
        "Sigmoid",
        "Tanh",
        "Leaky ReLU"
      ],
      "correctOptionIndex": 2,
      "explanation": "The DCGAN Generator's output layer typically uses Tanh activation to produce outputs in the range [-1, 1], which matches the normalized input data range.",
      "optionExplanations": [
        "Incorrect. ReLU is used in hidden layers but not the output layer of the Generator.",
        "Incorrect. Sigmoid produces outputs in [0, 1] range, which is less common for image generation.",
        "Correct. Tanh produces outputs in [-1, 1] range, suitable for normalized image data.",
        "Incorrect. Leaky ReLU is typically used in the Discriminator, not Generator output."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "activation_functions",
        "tanh",
        "DCGAN"
      ]
    },
    {
      "id": "GAN_015",
      "question": "What activation function is commonly used in the DCGAN Discriminator?",
      "options": [
        "ReLU",
        "Sigmoid",
        "Tanh",
        "Leaky ReLU"
      ],
      "correctOptionIndex": 3,
      "explanation": "DCGAN Discriminator commonly uses Leaky ReLU activation to prevent sparse gradients and allow small negative values to pass through.",
      "optionExplanations": [
        "Incorrect. Standard ReLU can cause sparse gradients which hurt GAN training.",
        "Incorrect. Sigmoid is typically used only in the final output layer for binary classification.",
        "Incorrect. Tanh is more commonly used in the Generator output, not Discriminator hidden layers.",
        "Correct. Leaky ReLU helps maintain gradient flow in the Discriminator."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "activation_functions",
        "leaky_relu",
        "discriminator"
      ]
    },
    {
      "id": "GAN_016",
      "question": "What is CycleGAN primarily designed for?",
      "options": [
        "Generating high-resolution images",
        "Image-to-image translation without paired data",
        "Text generation",
        "Video generation"
      ],
      "correctOptionIndex": 1,
      "explanation": "CycleGAN performs unpaired image-to-image translation, converting images from one domain to another without requiring paired training examples.",
      "optionExplanations": [
        "Incorrect. While CycleGAN can work with high-resolution images, this isn't its primary purpose.",
        "Correct. CycleGAN translates between image domains without needing paired training data.",
        "Incorrect. CycleGAN is designed for images, not text generation.",
        "Incorrect. CycleGAN focuses on static images, not video generation."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "CycleGAN",
        "image_translation",
        "unpaired_data"
      ]
    },
    {
      "id": "GAN_017",
      "question": "What is the key innovation of CycleGAN?",
      "options": [
        "Using attention mechanisms",
        "Cycle consistency loss",
        "Progressive growing",
        "Spectral normalization"
      ],
      "correctOptionIndex": 1,
      "explanation": "CycleGAN introduces cycle consistency loss, which ensures that translating an image from domain A to B and back to A should reconstruct the original image.",
      "optionExplanations": [
        "Incorrect. Attention mechanisms are used in other GAN variants but not CycleGAN's key innovation.",
        "Correct. Cycle consistency loss is the defining feature that enables unpaired translation.",
        "Incorrect. Progressive growing is associated with Progressive GANs, not CycleGAN.",
        "Incorrect. Spectral normalization is used in other GAN variants for training stability."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "CycleGAN",
        "cycle_consistency",
        "loss_function"
      ]
    },
    {
      "id": "GAN_018",
      "question": "How many generators does CycleGAN use?",
      "options": [
        "One",
        "Two",
        "Three",
        "Four"
      ],
      "correctOptionIndex": 1,
      "explanation": "CycleGAN uses two generators: one for translating from domain A to B, and another for translating from domain B to A.",
      "optionExplanations": [
        "Incorrect. A single generator cannot perform bidirectional translation.",
        "Correct. Two generators enable translation in both directions between domains.",
        "Incorrect. CycleGAN doesn't require three generators.",
        "Incorrect. Four generators would be unnecessarily complex for CycleGAN's purpose."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "CycleGAN",
        "architecture",
        "bidirectional"
      ]
    },
    {
      "id": "GAN_019",
      "question": "What is Pix2Pix GAN designed for?",
      "options": [
        "Unconditional image generation",
        "Paired image-to-image translation",
        "Text-to-image generation",
        "Image compression"
      ],
      "correctOptionIndex": 1,
      "explanation": "Pix2Pix is designed for supervised image-to-image translation tasks where paired training examples are available, such as converting sketches to photos.",
      "optionExplanations": [
        "Incorrect. Pix2Pix is conditional and requires input images, not unconditional generation.",
        "Correct. Pix2Pix performs image translation using paired training data.",
        "Incorrect. While some GANs do text-to-image, Pix2Pix focuses on image-to-image translation.",
        "Incorrect. Pix2Pix is for translation, not compression tasks."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "Pix2Pix",
        "paired_translation",
        "conditional"
      ]
    },
    {
      "id": "GAN_020",
      "question": "What loss function does Pix2Pix combine with adversarial loss?",
      "options": [
        "Cross-entropy loss",
        "L1 (Manhattan) loss",
        "L2 (Euclidean) loss",
        "Huber loss"
      ],
      "correctOptionIndex": 1,
      "explanation": "Pix2Pix combines adversarial loss with L1 loss to encourage the generated image to be close to the ground truth in terms of pixel values.",
      "optionExplanations": [
        "Incorrect. Cross-entropy is used for classification, not pixel-level reconstruction.",
        "Correct. L1 loss encourages pixel-wise similarity and reduces blurriness.",
        "Incorrect. L2 loss tends to produce blurrier results compared to L1 loss.",
        "Incorrect. Huber loss is not commonly used in Pix2Pix architecture."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "Pix2Pix",
        "L1_loss",
        "reconstruction"
      ]
    },
    {
      "id": "GAN_021",
      "question": "What is the main difference between Pix2Pix and CycleGAN?",
      "options": [
        "Pix2Pix uses more generators",
        "CycleGAN requires paired training data",
        "Pix2Pix requires paired training data, CycleGAN doesn't",
        "They serve the same purpose"
      ],
      "correctOptionIndex": 2,
      "explanation": "The key difference is that Pix2Pix requires paired training examples while CycleGAN can work with unpaired data from two different domains.",
      "optionExplanations": [
        "Incorrect. Pix2Pix uses one generator while CycleGAN uses two.",
        "Incorrect. CycleGAN specifically works with unpaired data.",
        "Correct. This is the fundamental difference in their data requirements.",
        "Incorrect. While both do image translation, their data requirements differ significantly."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "Pix2Pix",
        "CycleGAN",
        "paired_vs_unpaired"
      ]
    },
    {
      "id": "GAN_022",
      "question": "What is StyleGAN known for?",
      "options": [
        "Fast training speed",
        "Small model size",
        "High-quality face generation and style control",
        "Low computational requirements"
      ],
      "correctOptionIndex": 2,
      "explanation": "StyleGAN is renowned for generating extremely high-quality, photorealistic faces and providing fine-grained control over various style aspects of the generated images.",
      "optionExplanations": [
        "Incorrect. StyleGAN is computationally intensive and doesn't prioritize training speed.",
        "Incorrect. StyleGAN models are typically quite large due to their complexity.",
        "Correct. StyleGAN excels at generating realistic faces with controllable style features.",
        "Incorrect. StyleGAN requires significant computational resources."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "StyleGAN",
        "face_generation",
        "style_control"
      ]
    },
    {
      "id": "GAN_023",
      "question": "What is the key architectural innovation in StyleGAN?",
      "options": [
        "Progressive growing",
        "Style-based generator with adaptive instance normalization",
        "Attention mechanisms",
        "Residual connections"
      ],
      "correctOptionIndex": 1,
      "explanation": "StyleGAN introduces a style-based generator that uses adaptive instance normalization (AdaIN) to control style at different scales and resolutions.",
      "optionExplanations": [
        "Incorrect. Progressive growing was introduced in Progressive GAN, not StyleGAN.",
        "Correct. Style-based generation with AdaIN is StyleGAN's main innovation.",
        "Incorrect. Attention mechanisms are used in other architectures but not StyleGAN's key feature.",
        "Incorrect. While useful, residual connections are not StyleGAN's primary innovation."
      ],
      "difficulty": "HARD",
      "tags": [
        "StyleGAN",
        "AdaIN",
        "style_based_generation"
      ]
    },
    {
      "id": "GAN_024",
      "question": "What is Progressive GAN's main contribution?",
      "options": [
        "Faster inference",
        "Progressive growing of both generator and discriminator",
        "Better loss functions",
        "Reduced memory usage"
      ],
      "correctOptionIndex": 1,
      "explanation": "Progressive GAN introduces the technique of progressively growing both Generator and Discriminator networks during training, starting from low resolution and gradually increasing.",
      "optionExplanations": [
        "Incorrect. Progressive GAN focuses on training methodology, not inference speed.",
        "Correct. Progressive growing enables training of high-resolution generators more stably.",
        "Incorrect. The loss functions remain similar to other GANs.",
        "Incorrect. Progressive growing doesn't primarily aim to reduce memory usage."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "Progressive_GAN",
        "progressive_growing",
        "high_resolution"
      ]
    },
    {
      "id": "GAN_025",
      "question": "What problem does Progressive GAN's growing technique solve?",
      "options": [
        "Mode collapse",
        "Training instability at high resolutions",
        "Slow convergence",
        "Overfitting"
      ],
      "correctOptionIndex": 1,
      "explanation": "Progressive growing helps stabilize the training of high-resolution GANs by gradually increasing complexity, making it easier to learn fine details progressively.",
      "optionExplanations": [
        "Incorrect. Progressive growing doesn't directly address mode collapse.",
        "Correct. Starting small and growing progressively stabilizes high-resolution training.",
        "Incorrect. While it may help convergence, the primary goal is stability at high resolutions.",
        "Incorrect. Overfitting is not the main problem Progressive GAN addresses."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "Progressive_GAN",
        "training_stability",
        "high_resolution"
      ]
    },
    {
      "id": "GAN_026",
      "question": "What is BigGAN's primary achievement?",
      "options": [
        "Smallest model size",
        "Fastest training",
        "High-resolution conditional image generation",
        "Lowest computational cost"
      ],
      "correctOptionIndex": 2,
      "explanation": "BigGAN achieved state-of-the-art results in high-resolution conditional image generation by scaling up the model size and batch size significantly.",
      "optionExplanations": [
        "Incorrect. BigGAN is actually very large, as the name suggests.",
        "Incorrect. BigGAN requires extensive training time due to its size.",
        "Correct. BigGAN excels at generating high-quality, high-resolution conditional images.",
        "Incorrect. BigGAN has high computational requirements."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "BigGAN",
        "conditional_generation",
        "high_resolution"
      ]
    },
    {
      "id": "GAN_027",
      "question": "What technique does BigGAN use for training stability?",
      "options": [
        "Spectral normalization",
        "Progressive growing",
        "Cycle consistency",
        "Attention mechanisms"
      ],
      "correctOptionIndex": 0,
      "explanation": "BigGAN uses spectral normalization to constrain the Lipschitz constant of the discriminator, which helps stabilize training of large-scale GANs.",
      "optionExplanations": [
        "Correct. Spectral normalization is key to BigGAN's training stability.",
        "Incorrect. Progressive growing is associated with Progressive GAN, not BigGAN.",
        "Incorrect. Cycle consistency is used in CycleGAN.",
        "Incorrect. While attention can help, spectral normalization is BigGAN's primary stability technique."
      ],
      "difficulty": "HARD",
      "tags": [
        "BigGAN",
        "spectral_normalization",
        "training_stability"
      ]
    },
    {
      "id": "GAN_028",
      "question": "What is the main objective function in the original GAN formulation?",
      "options": [
        "Mean squared error",
        "Cross-entropy loss",
        "Minimax objective",
        "L1 loss"
      ],
      "correctOptionIndex": 2,
      "explanation": "GANs use a minimax objective where the Generator tries to minimize the objective while the Discriminator tries to maximize it, creating an adversarial game.",
      "optionExplanations": [
        "Incorrect. MSE is not the primary objective in GANs.",
        "Incorrect. While cross-entropy is used in the discriminator, the overall objective is minimax.",
        "Correct. The minimax game formulation is fundamental to GAN training.",
        "Incorrect. L1 loss is used in some variants but not the original GAN objective."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "minimax",
        "objective_function",
        "adversarial"
      ]
    },
    {
      "id": "GAN_029",
      "question": "What does the Generator try to minimize in the GAN objective?",
      "options": [
        "The probability of generated samples being detected as fake",
        "The reconstruction error",
        "The training time",
        "The model complexity"
      ],
      "correctOptionIndex": 0,
      "explanation": "The Generator aims to minimize the probability that the Discriminator correctly identifies its outputs as fake, essentially trying to maximize the Discriminator's error rate.",
      "optionExplanations": [
        "Correct. The Generator wants its samples to be classified as real by the Discriminator.",
        "Incorrect. Reconstruction error is not part of the standard GAN objective.",
        "Incorrect. Training time is not directly optimized by the Generator.",
        "Incorrect. Model complexity is not part of the Generator's objective function."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "generator_objective",
        "minimax",
        "adversarial"
      ]
    },
    {
      "id": "GAN_030",
      "question": "What does the Discriminator try to maximize in the GAN objective?",
      "options": [
        "The accuracy of distinguishing real from fake data",
        "The generation quality",
        "The training speed",
        "The model size"
      ],
      "correctOptionIndex": 0,
      "explanation": "The Discriminator tries to maximize its ability to correctly classify real data as real and fake data as fake, essentially maximizing classification accuracy.",
      "optionExplanations": [
        "Correct. The Discriminator wants to be as accurate as possible in detecting fake samples.",
        "Incorrect. Generation quality is the Generator's concern, not the Discriminator's objective.",
        "Incorrect. Training speed is not part of the Discriminator's objective function.",
        "Incorrect. Model size is not optimized by the Discriminator."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "discriminator_objective",
        "classification",
        "adversarial"
      ]
    },
    {
      "id": "GAN_031",
      "question": "What is Nash equilibrium in the context of GANs?",
      "options": [
        "When training stops completely",
        "When both networks reach optimal strategies and neither can improve unilaterally",
        "When the Generator always wins",
        "When the Discriminator becomes perfect"
      ],
      "correctOptionIndex": 1,
      "explanation": "Nash equilibrium in GANs occurs when both Generator and Discriminator reach optimal strategies such that neither can improve their performance by changing their strategy alone.",
      "optionExplanations": [
        "Incorrect. Nash equilibrium doesn't mean training stops, but rather optimal strategies are reached.",
        "Correct. Nash equilibrium represents the theoretical optimal point for both networks.",
        "Incorrect. In Nash equilibrium, neither network dominates the other.",
        "Incorrect. A perfect discriminator would prevent the generator from learning."
      ],
      "difficulty": "HARD",
      "tags": [
        "Nash_equilibrium",
        "game_theory",
        "optimization"
      ]
    },
    {
      "id": "GAN_032",
      "question": "What is the ideal value of the discriminator's output when Nash equilibrium is reached?",
      "options": [
        "0 for all inputs",
        "1 for all inputs",
        "0.5 for all inputs",
        "Random values"
      ],
      "correctOptionIndex": 2,
      "explanation": "At Nash equilibrium, the discriminator should output 0.5 for all inputs, indicating it cannot distinguish between real and generated data (both have equal probability).",
      "optionExplanations": [
        "Incorrect. Output of 0 would mean all data is classified as fake.",
        "Incorrect. Output of 1 would mean all data is classified as real.",
        "Correct. Output of 0.5 indicates perfect uncertainty, meaning generated data is indistinguishable from real data.",
        "Incorrect. Random values don't represent the optimal equilibrium state."
      ],
      "difficulty": "HARD",
      "tags": [
        "Nash_equilibrium",
        "discriminator_output",
        "optimal_state"
      ]
    },
    {
      "id": "GAN_033",
      "question": "What is one common symptom of training instability in GANs?",
      "options": [
        "Consistent loss decrease",
        "Oscillating losses",
        "Fast convergence",
        "Perfect generated samples"
      ],
      "correctOptionIndex": 1,
      "explanation": "Oscillating losses, where the generator and discriminator losses fluctuate dramatically, are a common sign of training instability in GANs.",
      "optionExplanations": [
        "Incorrect. Consistent loss decrease typically indicates stable, successful training.",
        "Correct. Oscillating losses indicate that neither network is converging to a stable solution.",
        "Incorrect. Fast convergence might indicate one network dominating, but not necessarily instability.",
        "Incorrect. Perfect samples would indicate successful training, not instability."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "training_instability",
        "oscillating_losses",
        "diagnosis"
      ]
    },
    {
      "id": "GAN_034",
      "question": "What is discriminator overpowering in GANs?",
      "options": [
        "When the discriminator becomes too large",
        "When the discriminator becomes perfect at classification, providing no useful gradients",
        "When the discriminator uses too much memory",
        "When the discriminator trains faster than the generator"
      ],
      "correctOptionIndex": 1,
      "explanation": "Discriminator overpowering occurs when the discriminator becomes too good at distinguishing real from fake, leading to vanishing gradients that prevent the generator from learning.",
      "optionExplanations": [
        "Incorrect. Size alone doesn't determine overpowering; performance does.",
        "Correct. A perfect discriminator provides zero gradients, stopping generator learning.",
        "Incorrect. Memory usage is not related to the overpowering problem.",
        "Incorrect. Training speed difference is not the definition of overpowering."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "discriminator_overpowering",
        "vanishing_gradients",
        "training_balance"
      ]
    },
    {
      "id": "GAN_035",
      "question": "What technique can help prevent discriminator overpowering?",
      "options": [
        "Training the discriminator more frequently",
        "Training the generator more frequently or using different learning rates",
        "Increasing batch size",
        "Using more complex architectures"
      ],
      "correctOptionIndex": 1,
      "explanation": "Training the generator more frequently than the discriminator or using different learning rates can help maintain balance and prevent discriminator overpowering.",
      "optionExplanations": [
        "Incorrect. Training discriminator more would worsen the overpowering problem.",
        "Correct. Adjusting training frequency or learning rates helps maintain balance.",
        "Incorrect. Batch size changes don't directly address the overpowering issue.",
        "Incorrect. Architecture complexity doesn't solve the training balance problem."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "training_balance",
        "learning_rates",
        "overpowering_prevention"
      ]
    },
    {
      "id": "GAN_036",
      "question": "What is the purpose of noise injection in GANs?",
      "options": [
        "To make training faster",
        "To reduce model size",
        "To provide randomness for diverse sample generation",
        "To improve memory efficiency"
      ],
      "correctOptionIndex": 2,
      "explanation": "Noise injection provides the source of randomness that allows GANs to generate diverse samples, as the generator maps different noise vectors to different outputs.",
      "optionExplanations": [
        "Incorrect. Noise injection doesn't directly impact training speed.",
        "Incorrect. Noise doesn't affect model size.",
        "Correct. Random noise enables the generation of diverse, varied samples.",
        "Incorrect. Noise injection doesn't improve memory efficiency."
      ],
      "difficulty": "EASY",
      "tags": [
        "noise_injection",
        "diversity",
        "randomness"
      ]
    },
    {
      "id": "GAN_037",
      "question": "What distribution is commonly used for the input noise in GANs?",
      "options": [
        "Bernoulli distribution",
        "Exponential distribution",
        "Normal (Gaussian) distribution",
        "Poisson distribution"
      ],
      "correctOptionIndex": 2,
      "explanation": "Normal (Gaussian) distribution is most commonly used for input noise in GANs, though uniform distribution is also popular. The choice affects the latent space properties.",
      "optionExplanations": [
        "Incorrect. Bernoulli distribution is binary and not commonly used for GAN noise.",
        "Incorrect. Exponential distribution is not standard for GAN input noise.",
        "Correct. Normal distribution is the most common choice for GAN noise input.",
        "Incorrect. Poisson distribution is used for count data, not GAN noise."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "noise_distribution",
        "gaussian",
        "latent_space"
      ]
    },
    {
      "id": "GAN_038",
      "question": "What is latent space interpolation in GANs?",
      "options": [
        "Changing the network architecture",
        "Gradually transitioning between different noise vectors to generate smooth transitions",
        "Adjusting learning rates during training",
        "Modifying the loss function"
      ],
      "correctOptionIndex": 1,
      "explanation": "Latent space interpolation involves smoothly transitioning between different points in the noise space to generate images that gradually morph from one to another.",
      "optionExplanations": [
        "Incorrect. Architecture changes are not related to latent space interpolation.",
        "Correct. Interpolation creates smooth transitions between generated samples.",
        "Incorrect. Learning rate adjustment is a training technique, not interpolation.",
        "Incorrect. Loss function modification is unrelated to latent space interpolation."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "latent_interpolation",
        "smooth_transitions",
        "latent_space"
      ]
    },
    {
      "id": "GAN_039",
      "question": "What does a smooth latent space interpolation indicate about a GAN?",
      "options": [
        "The model is overfitting",
        "The model has learned meaningful representations",
        "The training is unstable",
        "The model is underfitting"
      ],
      "correctOptionIndex": 1,
      "explanation": "Smooth interpolation in latent space indicates that the GAN has learned a meaningful and continuous representation where nearby points correspond to similar images.",
      "optionExplanations": [
        "Incorrect. Smooth interpolation typically indicates good generalization, not overfitting.",
        "Correct. Smooth transitions show the model has learned structured, meaningful representations.",
        "Incorrect. Smooth interpolation suggests stable, successful training.",
        "Incorrect. Underfitting would likely result in poor interpolation quality."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "latent_space_quality",
        "meaningful_representations",
        "interpolation"
      ]
    },
    {
      "id": "GAN_040",
      "question": "What is the Fr√©chet Inception Distance (FID) used for?",
      "options": [
        "Measuring training speed",
        "Evaluating the quality and diversity of generated images",
        "Optimizing network architecture",
        "Reducing computational cost"
      ],
      "correctOptionIndex": 1,
      "explanation": "FID measures the quality and diversity of generated images by comparing the statistics of features extracted from real and generated images using a pre-trained Inception network.",
      "optionExplanations": [
        "Incorrect. FID evaluates output quality, not training speed.",
        "Correct. FID is a standard metric for assessing GAN performance in terms of quality and diversity.",
        "Incorrect. FID is an evaluation metric, not an optimization tool.",
        "Incorrect. FID is a measurement tool, not a cost reduction technique."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "FID",
        "evaluation_metrics",
        "quality_assessment"
      ]
    },
    {
      "id": "GAN_041",
      "question": "What does a lower FID score indicate?",
      "options": [
        "Worse generation quality",
        "Better generation quality and similarity to real data",
        "Faster training",
        "Larger model size"
      ],
      "correctOptionIndex": 1,
      "explanation": "A lower FID score indicates better generation quality, meaning the generated images are more similar to real images in terms of feature distribution.",
      "optionExplanations": [
        "Incorrect. Lower FID scores indicate better, not worse, quality.",
        "Correct. Lower FID means generated images are more similar to real data distribution.",
        "Incorrect. FID measures quality, not training speed.",
        "Incorrect. FID is independent of model size."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "FID",
        "quality_metrics",
        "evaluation"
      ]
    },
    {
      "id": "GAN_042",
      "question": "What is the Inception Score (IS) designed to measure?",
      "options": [
        "Training time",
        "Model complexity",
        "Image quality and diversity",
        "Memory usage"
      ],
      "correctOptionIndex": 2,
      "explanation": "Inception Score measures both the quality (how realistic images look) and diversity (how varied the generated images are) of generated samples.",
      "optionExplanations": [
        "Incorrect. IS measures generated image properties, not training time.",
        "Incorrect. IS doesn't measure model complexity.",
        "Correct. IS evaluates both quality and diversity of generated images.",
        "Incorrect. IS is not related to memory usage measurement."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "inception_score",
        "quality_diversity",
        "evaluation"
      ]
    },
    {
      "id": "GAN_043",
      "question": "What characteristic indicates higher quality in Inception Score?",
      "options": [
        "Low entropy within individual images",
        "High entropy within individual images",
        "Random distribution",
        "Uniform predictions"
      ],
      "correctOptionIndex": 0,
      "explanation": "Higher quality is indicated by low entropy within individual images, meaning the classifier is confident about what class each generated image belongs to.",
      "optionExplanations": [
        "Correct. Low entropy means the classifier is confident, indicating clear, recognizable images.",
        "Incorrect. High entropy within images suggests unclear, low-quality generations.",
        "Incorrect. Random distribution doesn't indicate quality.",
        "Incorrect. Uniform predictions suggest the classifier can't recognize clear objects."
      ],
      "difficulty": "HARD",
      "tags": [
        "inception_score",
        "entropy",
        "quality_assessment"
      ]
    },
    {
      "id": "GAN_044",
      "question": "What is Wasserstein GAN (WGAN) designed to address?",
      "options": [
        "Slow inference speed",
        "Large model size",
        "Training instability and vanishing gradients",
        "High memory usage"
      ],
      "correctOptionIndex": 2,
      "explanation": "WGAN addresses training instability issues in traditional GANs by using Wasserstein distance instead of the original GAN loss, providing better gradient properties.",
      "optionExplanations": [
        "Incorrect. WGAN focuses on training stability, not inference speed.",
        "Incorrect. Model size is not WGAN's primary concern.",
        "Correct. WGAN improves training stability and provides meaningful gradients.",
        "Incorrect. Memory usage is not the main problem WGAN addresses."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "WGAN",
        "training_stability",
        "wasserstein_distance"
      ]
    },
    {
      "id": "GAN_045",
      "question": "What constraint does WGAN impose on the discriminator?",
      "options": [
        "Batch normalization requirement",
        "Lipschitz constraint",
        "Specific activation functions",
        "Fixed learning rate"
      ],
      "correctOptionIndex": 1,
      "explanation": "WGAN enforces a Lipschitz constraint on the discriminator (called critic in WGAN) to ensure the Wasserstein distance can be properly approximated.",
      "optionExplanations": [
        "Incorrect. Batch normalization is not the constraint WGAN imposes.",
        "Correct. Lipschitz constraint ensures the critic can approximate Wasserstein distance.",
        "Incorrect. WGAN doesn't require specific activation functions.",
        "Incorrect. Learning rate is not the constraint WGAN focuses on."
      ],
      "difficulty": "HARD",
      "tags": [
        "WGAN",
        "lipschitz_constraint",
        "critic"
      ]
    },
    {
      "id": "GAN_046",
      "question": "How does WGAN-GP improve upon the original WGAN?",
      "options": [
        "By using spectral normalization",
        "By implementing gradient penalty instead of weight clipping",
        "By adding attention mechanisms",
        "By using progressive growing"
      ],
      "correctOptionIndex": 1,
      "explanation": "WGAN-GP (Gradient Penalty) replaces weight clipping with a gradient penalty term to enforce the Lipschitz constraint more effectively and stably.",
      "optionExplanations": [
        "Incorrect. Spectral normalization is used in other GAN variants, not WGAN-GP's innovation.",
        "Correct. Gradient penalty provides a better way to enforce Lipschitz constraint than weight clipping.",
        "Incorrect. Attention mechanisms are not part of WGAN-GP's improvement.",
        "Incorrect. Progressive growing is associated with different GAN variants."
      ],
      "difficulty": "HARD",
      "tags": [
        "WGAN-GP",
        "gradient_penalty",
        "lipschitz_enforcement"
      ]
    },
    {
      "id": "GAN_047",
      "question": "What is conditional GAN (cGAN)?",
      "options": [
        "A GAN that works only under specific conditions",
        "A GAN that generates samples based on additional input information",
        "A GAN with conditional probability layers",
        "A GAN that requires conditional optimization"
      ],
      "correctOptionIndex": 1,
      "explanation": "Conditional GAN generates samples based on additional input information (like class labels), allowing controlled generation of specific types of data.",
      "optionExplanations": [
        "Incorrect. 'Conditional' doesn't refer to operational conditions.",
        "Correct. cGAN takes additional input to control what type of sample to generate.",
        "Incorrect. It doesn't necessarily use conditional probability layers.",
        "Incorrect. The conditioning refers to the input, not the optimization process."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "conditional_GAN",
        "controlled_generation",
        "class_labels"
      ]
    },
    {
      "id": "GAN_048",
      "question": "What additional input does a conditional GAN typically receive?",
      "options": [
        "Random noise only",
        "Class labels or other conditioning information",
        "Previous generated samples",
        "Training loss values"
      ],
      "correctOptionIndex": 1,
      "explanation": "Conditional GANs receive class labels, text descriptions, or other conditioning information alongside random noise to control the generation process.",
      "optionExplanations": [
        "Incorrect. Conditional GANs receive both noise and conditioning information.",
        "Correct. Additional conditioning information guides the generation process.",
        "Incorrect. Previous samples are not typically used as conditioning input.",
        "Incorrect. Loss values are not conditioning inputs for generation."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "conditional_input",
        "class_labels",
        "conditioning"
      ]
    },
    {
      "id": "GAN_049",
      "question": "What is InfoGAN designed to learn?",
      "options": [
        "Faster training procedures",
        "Disentangled representations in the latent space",
        "Smaller model architectures",
        "Better loss functions"
      ],
      "correctOptionIndex": 1,
      "explanation": "InfoGAN learns disentangled representations by maximizing mutual information between a subset of latent variables and the generated data, allowing control over specific features.",
      "optionExplanations": [
        "Incorrect. InfoGAN focuses on representation learning, not training speed.",
        "Correct. InfoGAN learns to separate different factors of variation in the latent space.",
        "Incorrect. Model architecture size is not InfoGAN's primary concern.",
        "Incorrect. While it modifies the objective, the goal is disentanglement, not just better loss."
      ],
      "difficulty": "HARD",
      "tags": [
        "InfoGAN",
        "disentangled_representations",
        "mutual_information"
      ]
    },
    {
      "id": "GAN_050",
      "question": "What mathematical concept does InfoGAN optimize to achieve disentanglement?",
      "options": [
        "Cross-entropy",
        "Mutual information",
        "KL divergence only",
        "Mean squared error"
      ],
      "correctOptionIndex": 1,
      "explanation": "InfoGAN maximizes mutual information between specific latent codes and the generated output, encouraging the generator to use these codes for meaningful, disentangled features.",
      "optionExplanations": [
        "Incorrect. Cross-entropy is used in classification but not for disentanglement in InfoGAN.",
        "Correct. Mutual information maximization drives the disentanglement process.",
        "Incorrect. KL divergence is used but mutual information is the key concept.",
        "Incorrect. MSE is not the primary tool for achieving disentanglement in InfoGAN."
      ],
      "difficulty": "HARD",
      "tags": [
        "mutual_information",
        "disentanglement",
        "InfoGAN"
      ]
    },
    {
      "id": "GAN_051",
      "question": "What is the main advantage of disentangled representations?",
      "options": [
        "Faster training",
        "Smaller models",
        "Controllable and interpretable generation",
        "Better image quality"
      ],
      "correctOptionIndex": 2,
      "explanation": "Disentangled representations allow for controllable generation where specific latent dimensions correspond to interpretable features like pose, lighting, or facial attributes.",
      "optionExplanations": [
        "Incorrect. Disentanglement doesn't necessarily speed up training.",
        "Incorrect. Model size is not the primary benefit of disentanglement.",
        "Correct. Disentanglement enables fine-grained control over specific attributes.",
        "Incorrect. While quality may improve, controllability is the main advantage."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "disentanglement",
        "controllability",
        "interpretability"
      ]
    },
    {
      "id": "GAN_052",
      "question": "What is the main challenge in training GANs?",
      "options": [
        "High memory requirements",
        "Slow inference",
        "Achieving stable convergence",
        "Complex data preprocessing"
      ],
      "correctOptionIndex": 2,
      "explanation": "The main challenge in GAN training is achieving stable convergence due to the adversarial nature of training two networks simultaneously, which can lead to various instabilities.",
      "optionExplanations": [
        "Incorrect. While GANs can be memory-intensive, this isn't the primary challenge.",
        "Incorrect. Inference speed is generally not the main training challenge.",
        "Correct. Stable convergence is notoriously difficult due to the adversarial training dynamics.",
        "Incorrect. Data preprocessing is typically straightforward for GANs."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "training_challenges",
        "convergence",
        "stability"
      ]
    },
    {
      "id": "GAN_053",
      "question": "What is spectral normalization in GANs?",
      "options": [
        "A data preprocessing technique",
        "A technique to constrain the spectral norm of weight matrices",
        "A loss function modification",
        "An activation function"
      ],
      "correctOptionIndex": 1,
      "explanation": "Spectral normalization constrains the spectral norm (largest singular value) of weight matrices in the discriminator to improve training stability and control Lipschitz constants.",
      "optionExplanations": [
        "Incorrect. Spectral normalization is applied to network weights, not data preprocessing.",
        "Correct. It constrains the largest singular value of weight matrices for stability.",
        "Incorrect. It's a weight constraint technique, not a loss function change.",
        "Incorrect. Spectral normalization is not an activation function."
      ],
      "difficulty": "HARD",
      "tags": [
        "spectral_normalization",
        "weight_constraints",
        "training_stability"
      ]
    },
    {
      "id": "GAN_054",
      "question": "Why is spectral normalization beneficial for GAN training?",
      "options": [
        "It reduces computational cost",
        "It improves training stability by controlling Lipschitz constants",
        "It increases generation speed",
        "It reduces model size"
      ],
      "correctOptionIndex": 1,
      "explanation": "Spectral normalization improves training stability by controlling the Lipschitz constant of the discriminator, preventing gradient explosion and helping maintain training balance.",
      "optionExplanations": [
        "Incorrect. Spectral normalization doesn't primarily reduce computational cost.",
        "Correct. Controlling Lipschitz constants leads to more stable training dynamics.",
        "Incorrect. It affects training stability, not generation speed.",
        "Incorrect. Model size is not significantly affected by spectral normalization."
      ],
      "difficulty": "HARD",
      "tags": [
        "spectral_normalization",
        "lipschitz_constants",
        "training_stability"
      ]
    },
    {
      "id": "GAN_055",
      "question": "What is self-attention in the context of GANs?",
      "options": [
        "A technique for the generator to examine its own outputs",
        "A mechanism allowing the model to focus on different spatial locations",
        "A method for automatic hyperparameter tuning",
        "A regularization technique"
      ],
      "correctOptionIndex": 1,
      "explanation": "Self-attention in GANs (like SAGAN) allows the model to attend to different spatial locations when generating each part of an image, capturing long-range dependencies.",
      "optionExplanations": [
        "Incorrect. Self-attention doesn't involve examining previous outputs.",
        "Correct. Self-attention enables the model to focus on relevant spatial locations.",
        "Incorrect. Self-attention is not used for hyperparameter tuning.",
        "Incorrect. While it may have regularizing effects, it's primarily an attention mechanism."
      ],
      "difficulty": "HARD",
      "tags": [
        "self_attention",
        "spatial_attention",
        "SAGAN"
      ]
    },
    {
      "id": "GAN_056",
      "question": "What problem does self-attention help solve in image generation?",
      "options": [
        "Mode collapse",
        "Long-range spatial dependencies",
        "Training speed",
        "Memory usage"
      ],
      "correctOptionIndex": 1,
      "explanation": "Self-attention helps GANs capture long-range spatial dependencies in images, which convolutional layers alone struggle with due to their local receptive fields.",
      "optionExplanations": [
        "Incorrect. Self-attention doesn't directly address mode collapse.",
        "Correct. Self-attention enables modeling of long-range spatial relationships.",
        "Incorrect. Self-attention typically slows training due to computational overhead.",
        "Incorrect. Self-attention generally increases memory usage."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "self_attention",
        "long_range_dependencies",
        "spatial_modeling"
      ]
    },
    {
      "id": "GAN_057",
      "question": "What is the difference between traditional GAN loss and least squares GAN (LSGAN) loss?",
      "options": [
        "LSGAN uses cross-entropy while traditional uses MSE",
        "LSGAN uses least squares loss instead of cross-entropy",
        "LSGAN uses L1 loss",
        "There is no difference"
      ],
      "correctOptionIndex": 1,
      "explanation": "LSGAN replaces the traditional cross-entropy loss with least squares loss to address the vanishing gradient problem and provide more stable training.",
      "optionExplanations": [
        "Incorrect. This reverses the actual relationship between the two approaches.",
        "Correct. LSGAN uses least squares instead of traditional cross-entropy loss.",
        "Incorrect. LSGAN specifically uses least squares (L2) loss, not L1.",
        "Incorrect. The loss functions are fundamentally different."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "LSGAN",
        "least_squares_loss",
        "loss_functions"
      ]
    },
    {
      "id": "GAN_058",
      "question": "What advantage does LSGAN offer over traditional GANs?",
      "options": [
        "Faster training",
        "Smaller model size",
        "Better gradient properties and more stable training",
        "Lower computational cost"
      ],
      "correctOptionIndex": 2,
      "explanation": "LSGAN provides better gradient properties, especially when the discriminator becomes too confident, leading to more stable training compared to traditional GANs.",
      "optionExplanations": [
        "Incorrect. Training speed is not the primary advantage of LSGAN.",
        "Incorrect. Model size is not affected by the choice of loss function.",
        "Correct. LSGAN provides more stable gradients and training dynamics.",
        "Incorrect. Computational cost is similar between LSGAN and traditional GANs."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "LSGAN",
        "gradient_properties",
        "training_stability"
      ]
    },
    {
      "id": "GAN_059",
      "question": "What is the primary application domain where GANs have shown exceptional results?",
      "options": [
        "Time series prediction",
        "Image generation and manipulation",
        "Natural language processing",
        "Recommendation systems"
      ],
      "correctOptionIndex": 1,
      "explanation": "GANs have achieved their most remarkable success in image generation and manipulation tasks, producing photorealistic images and enabling various image-to-image translation applications.",
      "optionExplanations": [
        "Incorrect. While GANs can be used for time series, images are their primary strength.",
        "Correct. Image generation has been GANs' most successful application domain.",
        "Incorrect. GANs in NLP face challenges and are less commonly used than in vision.",
        "Incorrect. Recommendation systems typically use other approaches more effectively."
      ],
      "difficulty": "EASY",
      "tags": [
        "applications",
        "image_generation",
        "computer_vision"
      ]
    },
    {
      "id": "GAN_060",
      "question": "What makes GANs particularly suitable for image generation?",
      "options": [
        "Low computational requirements",
        "Ability to capture complex visual patterns and spatial relationships",
        "Simplicity of implementation",
        "Guaranteed convergence"
      ],
      "correctOptionIndex": 1,
      "explanation": "GANs excel at image generation because they can learn and reproduce complex visual patterns, textures, and spatial relationships present in natural images.",
      "optionExplanations": [
        "Incorrect. GANs typically have high computational requirements.",
        "Correct. GANs are excellent at learning complex visual and spatial patterns.",
        "Incorrect. GANs are notoriously difficult to implement and tune properly.",
        "Incorrect. GANs do not guarantee convergence and can be unstable."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "image_generation",
        "visual_patterns",
        "spatial_relationships"
      ]
    },
    {
      "id": "GAN_061",
      "question": "What is data augmentation using GANs?",
      "options": [
        "Using GANs to compress training data",
        "Using GANs to generate additional synthetic training samples",
        "Using GANs to clean noisy data",
        "Using GANs to reduce dataset size"
      ],
      "correctOptionIndex": 1,
      "explanation": "Data augmentation with GANs involves generating additional synthetic training samples to increase dataset size and diversity, especially useful when labeled data is scarce.",
      "optionExplanations": [
        "Incorrect. GANs generate data, they don't compress it.",
        "Correct. GANs can create synthetic samples to augment training datasets.",
        "Incorrect. While GANs might be used for denoising, this isn't data augmentation.",
        "Incorrect. Data augmentation increases dataset size, not reduces it."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "data_augmentation",
        "synthetic_data",
        "dataset_expansion"
      ]
    },
    {
      "id": "GAN_062",
      "question": "What is super-resolution in the context of GANs?",
      "options": [
        "Generating images faster",
        "Enhancing low-resolution images to high-resolution",
        "Reducing image file sizes",
        "Converting color images to grayscale"
      ],
      "correctOptionIndex": 1,
      "explanation": "Super-resolution GANs (like SRGAN) enhance low-resolution images by generating high-resolution versions with realistic details and textures.",
      "optionExplanations": [
        "Incorrect. Super-resolution refers to image quality, not generation speed.",
        "Correct. Super-resolution increases image resolution while maintaining or improving quality.",
        "Incorrect. This would be compression, not super-resolution.",
        "Incorrect. Color conversion is not related to super-resolution."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "super_resolution",
        "SRGAN",
        "image_enhancement"
      ]
    },
    {
      "id": "GAN_063",
      "question": "What is style transfer using GANs?",
      "options": [
        "Transferring model weights between networks",
        "Applying the artistic style of one image to the content of another",
        "Moving data between different domains",
        "Changing the file format of images"
      ],
      "correctOptionIndex": 1,
      "explanation": "Style transfer with GANs involves applying the artistic style (textures, colors, brushstrokes) of one image to the content structure of another image.",
      "optionExplanations": [
        "Incorrect. Style transfer operates on image content, not model weights.",
        "Correct. Style transfer combines content from one image with style from another.",
        "Incorrect. While domain transfer exists, style transfer specifically refers to artistic style.",
        "Incorrect. File format conversion is not style transfer."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "style_transfer",
        "artistic_style",
        "content_preservation"
      ]
    },
    {
      "id": "GAN_064",
      "question": "What is inpainting in computer vision, and how do GANs help?",
      "options": [
        "Adding colors to grayscale images",
        "Filling in missing or corrupted parts of images",
        "Reducing image noise",
        "Compressing image files"
      ],
      "correctOptionIndex": 1,
      "explanation": "Inpainting involves filling in missing, corrupted, or unwanted parts of images. GANs help by generating realistic content that seamlessly blends with the existing image.",
      "optionExplanations": [
        "Incorrect. This describes colorization, not inpainting.",
        "Correct. Inpainting fills missing regions with plausible content using GANs.",
        "Incorrect. Noise reduction is denoising, not inpainting.",
        "Incorrect. Compression is unrelated to inpainting."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "inpainting",
        "image_completion",
        "missing_regions"
      ]
    },
    {
      "id": "GAN_065",
      "question": "What ethical concerns are associated with GANs?",
      "options": [
        "High computational costs",
        "Creation of deepfakes and misinformation",
        "Patent infringement",
        "Slow training times"
      ],
      "correctOptionIndex": 1,
      "explanation": "A major ethical concern with GANs is their ability to create highly realistic deepfakes, which can be used for misinformation, identity theft, and non-consensual content creation.",
      "optionExplanations": [
        "Incorrect. Computational costs are a practical, not ethical concern.",
        "Correct. Deepfakes pose serious ethical and societal risks.",
        "Incorrect. Patent issues are legal, not specifically ethical concerns.",
        "Incorrect. Training time is a technical limitation, not an ethical issue."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "ethics",
        "deepfakes",
        "misinformation"
      ]
    },
    {
      "id": "GAN_066",
      "question": "What is a deepfake?",
      "options": [
        "A compressed video format",
        "A synthetic media where a person appears to say or do things they never did",
        "A type of neural network architecture",
        "A data preprocessing technique"
      ],
      "correctOptionIndex": 1,
      "explanation": "Deepfakes are synthetic media created using GANs where someone appears to say or do things they never actually did, often involving face swapping or voice synthesis.",
      "optionExplanations": [
        "Incorrect. Deepfakes are synthetic content, not a compression format.",
        "Correct. Deepfakes create realistic but fake audio-visual content of people.",
        "Incorrect. While GANs create deepfakes, deepfake itself isn't an architecture.",
        "Incorrect. Deepfakes are the output, not a preprocessing technique."
      ],
      "difficulty": "EASY",
      "tags": [
        "deepfakes",
        "synthetic_media",
        "face_swapping"
      ]
    },
    {
      "id": "GAN_067",
      "question": "What is domain adaptation in the context of GANs?",
      "options": [
        "Adapting network architecture for different tasks",
        "Transferring knowledge from one data domain to another",
        "Changing the loss function",
        "Adjusting learning rates"
      ],
      "correctOptionIndex": 1,
      "explanation": "Domain adaptation with GANs involves transferring knowledge or models trained on one domain (like synthetic data) to work well on another domain (like real data).",
      "optionExplanations": [
        "Incorrect. Domain adaptation focuses on data domains, not architecture changes.",
        "Correct. Domain adaptation transfers learning between different data distributions.",
        "Incorrect. Loss function changes may be involved but aren't the definition of domain adaptation.",
        "Incorrect. Learning rate adjustment is a training technique, not domain adaptation."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "domain_adaptation",
        "knowledge_transfer",
        "data_domains"
      ]
    },
    {
      "id": "GAN_068",
      "question": "What is adversarial training in the broader context beyond GANs?",
      "options": [
        "Training models to be robust against adversarial attacks",
        "Training multiple models simultaneously",
        "Using multiple loss functions",
        "Training with noisy data"
      ],
      "correctOptionIndex": 0,
      "explanation": "Adversarial training in cybersecurity and robust ML involves training models to be resistant to adversarial examples - inputs designed to fool the model.",
      "optionExplanations": [
        "Correct. Adversarial training builds robustness against malicious inputs.",
        "Incorrect. This is ensemble training, not specifically adversarial training.",
        "Incorrect. Multiple loss functions don't define adversarial training.",
        "Incorrect. Noisy data training is different from adversarial training."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "adversarial_training",
        "robustness",
        "adversarial_attacks"
      ]
    },
    {
      "id": "GAN_069",
      "question": "What is the relationship between VAEs and GANs?",
      "options": [
        "They are identical architectures",
        "Both are generative models but use different approaches",
        "VAEs are a subset of GANs",
        "GANs are a subset of VAEs"
      ],
      "correctOptionIndex": 1,
      "explanation": "Variational Autoencoders (VAEs) and GANs are both generative models but use different approaches: VAEs use probabilistic encoding-decoding while GANs use adversarial training.",
      "optionExplanations": [
        "Incorrect. VAEs and GANs have fundamentally different architectures.",
        "Correct. Both generate data but through different mathematical frameworks.",
        "Incorrect. VAEs and GANs are separate generative model families.",
        "Incorrect. GANs and VAEs are distinct, neither is a subset of the other."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "VAE",
        "generative_models",
        "comparison"
      ]
    },
    {
      "id": "GAN_070",
      "question": "What advantage do GANs have over VAEs?",
      "options": [
        "Guaranteed convergence",
        "Easier training",
        "Generally sharper, more realistic generated images",
        "Lower computational cost"
      ],
      "correctOptionIndex": 2,
      "explanation": "GANs typically produce sharper, more realistic images compared to VAEs, which often generate blurry outputs due to their reconstruction loss formulation.",
      "optionExplanations": [
        "Incorrect. GANs actually have less guaranteed convergence than VAEs.",
        "Incorrect. GANs are notoriously difficult to train compared to VAEs.",
        "Correct. GANs excel at generating sharp, realistic images.",
        "Incorrect. GANs typically have similar or higher computational costs than VAEs."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "GAN_vs_VAE",
        "image_quality",
        "sharpness"
      ]
    },
    {
      "id": "GAN_071",
      "question": "What is the main disadvantage of GANs compared to VAEs?",
      "options": [
        "Lower image quality",
        "Training instability and difficulty",
        "Higher memory usage",
        "Slower inference"
      ],
      "correctOptionIndex": 1,
      "explanation": "The main disadvantage of GANs is their training instability and difficulty in achieving convergence, unlike VAEs which have more stable training dynamics.",
      "optionExplanations": [
        "Incorrect. GANs generally produce higher quality images than VAEs.",
        "Correct. Training instability is GANs' most significant drawback.",
        "Incorrect. Memory usage is not necessarily higher for GANs.",
        "Incorrect. Inference speed is not typically slower for GANs."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "GAN_disadvantages",
        "training_stability",
        "comparison"
      ]
    },
    {
      "id": "GAN_072",
      "question": "What is transfer learning in the context of GANs?",
      "options": [
        "Transferring data between networks",
        "Using pre-trained GANs as starting points for new tasks",
        "Converting GANs to other architectures",
        "Sharing weights between generator and discriminator"
      ],
      "correctOptionIndex": 1,
      "explanation": "Transfer learning with GANs involves using pre-trained GAN models as starting points and fine-tuning them for new, related tasks or datasets.",
      "optionExplanations": [
        "Incorrect. Transfer learning involves model weights, not data transfer.",
        "Correct. Pre-trained GANs can be fine-tuned for new tasks.",
        "Incorrect. Architecture conversion is not transfer learning.",
        "Incorrect. Weight sharing between components is not transfer learning."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "transfer_learning",
        "pre_trained_models",
        "fine_tuning"
      ]
    },
    {
      "id": "GAN_073",
      "question": "What is feature matching in GAN training?",
      "options": [
        "Matching features between real and generated images",
        "A technique to match intermediate feature representations",
        "Matching network architectures",
        "Matching training data"
      ],
      "correctOptionIndex": 1,
      "explanation": "Feature matching is a training technique where the generator is trained to match the statistics of intermediate feature representations from the discriminator, rather than just fooling it.",
      "optionExplanations": [
        "Incorrect. Feature matching operates on intermediate features, not final image features.",
        "Correct. Feature matching focuses on intermediate layer representations.",
        "Incorrect. Architecture matching is not what feature matching refers to.",
        "Incorrect. Data matching is not the purpose of feature matching."
      ],
      "difficulty": "HARD",
      "tags": [
        "feature_matching",
        "intermediate_features",
        "training_technique"
      ]
    },
    {
      "id": "GAN_074",
      "question": "What is historical averaging in GAN training?",
      "options": [
        "Averaging multiple generated samples",
        "Using historical parameter values in the loss function",
        "Averaging training losses over time",
        "Using historical training data"
      ],
      "correctOptionIndex": 1,
      "explanation": "Historical averaging adds a penalty term to the loss function based on the difference between current parameters and a running average of historical parameters to reduce oscillations.",
      "optionExplanations": [
        "Incorrect. Historical averaging operates on parameters, not generated samples.",
        "Correct. It uses historical parameter values to stabilize training.",
        "Incorrect. It's about parameter history, not loss averaging.",
        "Incorrect. It doesn't involve using historical training data."
      ],
      "difficulty": "HARD",
      "tags": [
        "historical_averaging",
        "parameter_stabilization",
        "training_technique"
      ]
    },
    {
      "id": "GAN_075",
      "question": "What is the purpose of experience replay in GAN training?",
      "options": [
        "To speed up training",
        "To store and reuse previously generated samples",
        "To reduce memory usage",
        "To improve model architecture"
      ],
      "correctOptionIndex": 1,
      "explanation": "Experience replay in GANs involves storing previously generated samples and occasionally retraining the discriminator on them to prevent it from forgetting how to detect older generated samples.",
      "optionExplanations": [
        "Incorrect. Experience replay doesn't primarily aim to speed up training.",
        "Correct. It stores and reuses past generated samples for discriminator training.",
        "Incorrect. Experience replay actually increases memory usage by storing samples.",
        "Incorrect. It's a training technique, not an architectural improvement."
      ],
      "difficulty": "HARD",
      "tags": [
        "experience_replay",
        "sample_storage",
        "discriminator_training"
      ]
    },
    {
      "id": "GAN_076",
      "question": "What is unrolled GANs?",
      "options": [
        "GANs with unrolled network architectures",
        "GANs where the generator is updated considering future discriminator updates",
        "GANs that process sequences",
        "GANs with reduced parameters"
      ],
      "correctOptionIndex": 1,
      "explanation": "Unrolled GANs update the generator by considering how the discriminator will respond to future generator updates, helping to address training instabilities.",
      "optionExplanations": [
        "Incorrect. Unrolling refers to optimization strategy, not architecture.",
        "Correct. The generator considers future discriminator responses in its updates.",
        "Incorrect. Unrolling is not specifically for sequence processing.",
        "Incorrect. Parameter reduction is not the goal of unrolled GANs."
      ],
      "difficulty": "HARD",
      "tags": [
        "unrolled_GANs",
        "future_updates",
        "training_stability"
      ]
    },
    {
      "id": "GAN_077",
      "question": "What is the main idea behind Progressive GANs?",
      "options": [
        "Training multiple GANs simultaneously",
        "Gradually increasing the resolution during training",
        "Using progressive loss functions",
        "Progressively reducing model size"
      ],
      "correctOptionIndex": 1,
      "explanation": "Progressive GANs start training at low resolution and gradually add layers to increase resolution during training, making high-resolution generation more stable.",
      "optionExplanations": [
        "Incorrect. Progressive GANs involve one GAN growing, not multiple GANs.",
        "Correct. Resolution is gradually increased by adding layers during training.",
        "Incorrect. The loss functions don't change progressively.",
        "Incorrect. Model size increases, not decreases, during progressive training."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "Progressive_GANs",
        "resolution_growing",
        "stable_training"
      ]
    },
    {
      "id": "GAN_078",
      "question": "What is the advantage of progressive growing in GANs?",
      "options": [
        "Faster inference",
        "More stable training of high-resolution generators",
        "Smaller final model size",
        "Lower computational cost"
      ],
      "correctOptionIndex": 1,
      "explanation": "Progressive growing enables more stable training of high-resolution GANs by gradually increasing complexity, avoiding the difficulties of training high-resolution models from scratch.",
      "optionExplanations": [
        "Incorrect. Progressive growing affects training stability, not inference speed.",
        "Correct. It provides a stable path to high-resolution generation.",
        "Incorrect. The final model size is typically larger, not smaller.",
        "Incorrect. Total computational cost is not necessarily lower."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "progressive_growing",
        "high_resolution",
        "training_stability"
      ]
    },
    {
      "id": "GAN_079",
      "question": "What is Self-Attention GAN (SAGAN)?",
      "options": [
        "A GAN that generates self-portraits",
        "A GAN that uses attention mechanisms for long-range dependencies",
        "A GAN that trains itself without supervision",
        "A GAN that focuses on a single object"
      ],
      "correctOptionIndex": 1,
      "explanation": "SAGAN incorporates self-attention mechanisms that allow the model to attend to distant spatial locations when generating each part of an image, capturing long-range dependencies.",
      "optionExplanations": [
        "Incorrect. SAGAN's name doesn't refer to self-portrait generation.",
        "Correct. SAGAN uses self-attention to model long-range spatial dependencies.",
        "Incorrect. All GANs are unsupervised; this isn't SAGAN's unique feature.",
        "Incorrect. SAGAN can generate complex scenes, not just single objects."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "SAGAN",
        "self_attention",
        "long_range_dependencies"
      ]
    },
    {
      "id": "GAN_080",
      "question": "What problem does SAGAN address that previous GANs struggled with?",
      "options": [
        "Training speed",
        "Memory efficiency",
        "Generating coherent structure in images with long-range dependencies",
        "Color accuracy"
      ],
      "correctOptionIndex": 2,
      "explanation": "SAGAN addresses the problem of generating images with coherent global structure by enabling the model to consider long-range spatial dependencies through self-attention.",
      "optionExplanations": [
        "Incorrect. SAGAN doesn't primarily focus on training speed improvements.",
        "Incorrect. Self-attention typically increases memory usage.",
        "Correct. SAGAN improves global coherence in generated images.",
        "Incorrect. Color accuracy is not the main problem SAGAN addresses."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "SAGAN",
        "global_coherence",
        "spatial_dependencies"
      ]
    },
    {
      "id": "GAN_081",
      "question": "What is BigBiGAN?",
      "options": [
        "A very large version of BigGAN",
        "A bidirectional GAN that can both generate and encode",
        "A GAN for big data applications",
        "A GAN with two generators"
      ],
      "correctOptionIndex": 1,
      "explanation": "BigBiGAN is a bidirectional GAN that extends BigGAN with an encoder, allowing both generation from latent codes and encoding of real images to latent space.",
      "optionExplanations": [
        "Incorrect. BigBiGAN is bidirectional, not just a larger version.",
        "Correct. BigBiGAN can both generate images and encode them to latent space.",
        "Incorrect. The name doesn't refer to big data applications.",
        "Incorrect. BigBiGAN has one generator and one encoder."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "BigBiGAN",
        "bidirectional",
        "encoder"
      ]
    },
    {
      "id": "GAN_082",
      "question": "What is the main advantage of bidirectional GANs like BigBiGAN?",
      "options": [
        "Faster training",
        "Ability to encode real images into latent space",
        "Better image quality",
        "Smaller model size"
      ],
      "correctOptionIndex": 1,
      "explanation": "Bidirectional GANs can encode real images into the latent space, enabling applications like image editing, interpolation, and analysis of the learned representations.",
      "optionExplanations": [
        "Incorrect. Bidirectional GANs don't necessarily train faster.",
        "Correct. The encoder allows mapping real images to latent codes.",
        "Incorrect. While quality may be good, encoding capability is the main advantage.",
        "Incorrect. Bidirectional GANs are typically larger due to the additional encoder."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "bidirectional_GANs",
        "encoding",
        "latent_space"
      ]
    },
    {
      "id": "GAN_083",
      "question": "What is the typical approach for handling different image resolutions in DCGAN?",
      "options": [
        "Using the same architecture for all resolutions",
        "Adjusting the number of layers based on target resolution",
        "Using different activation functions",
        "Changing the loss function"
      ],
      "correctOptionIndex": 1,
      "explanation": "DCGANs typically adjust the number of convolutional and transpose convolutional layers based on the target image resolution, with each layer handling a specific scale.",
      "optionExplanations": [
        "Incorrect. Different resolutions require different network depths.",
        "Correct. Layer count is adjusted to match the desired output resolution.",
        "Incorrect. Activation functions typically remain consistent across resolutions.",
        "Incorrect. Loss functions don't need to change for different resolutions."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "DCGAN",
        "resolution_handling",
        "layer_depth"
      ]
    },
    {
      "id": "GAN_084",
      "question": "What is mode seeking behavior in GANs?",
      "options": [
        "When the generator explores different modes of the data distribution",
        "When the generator finds and sticks to easy-to-generate samples",
        "When the discriminator seeks specific modes",
        "When training seeks the optimal mode"
      ],
      "correctOptionIndex": 1,
      "explanation": "Mode seeking behavior occurs when the generator finds samples that easily fool the discriminator and repeatedly generates similar samples, leading to reduced diversity.",
      "optionExplanations": [
        "Incorrect. Mode seeking involves limited exploration, not diverse exploration.",
        "Correct. The generator exploits weaknesses in the discriminator by generating similar samples.",
        "Incorrect. Mode seeking is a generator behavior, not discriminator behavior.",
        "Incorrect. Mode seeking is typically undesirable, not optimal."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "mode_seeking",
        "generator_behavior",
        "diversity_loss"
      ]
    },
    {
      "id": "GAN_085",
      "question": "What is the relationship between mode collapse and mode seeking?",
      "options": [
        "They are the same phenomenon",
        "Mode seeking can lead to mode collapse",
        "They are opposite behaviors",
        "They are unrelated"
      ],
      "correctOptionIndex": 1,
      "explanation": "Mode seeking behavior, where the generator finds easy-to-fool samples, can eventually lead to mode collapse if the generator becomes stuck generating only these limited types of samples.",
      "optionExplanations": [
        "Incorrect. While related, mode seeking and mode collapse are distinct phenomena.",
        "Correct. Mode seeking behavior can evolve into full mode collapse over time.",
        "Incorrect. They are related behaviors, not opposites.",
        "Incorrect. Mode seeking and mode collapse are closely related phenomena."
      ],
      "difficulty": "HARD",
      "tags": [
        "mode_collapse",
        "mode_seeking",
        "training_dynamics"
      ]
    },
    {
      "id": "GAN_086",
      "question": "What is the purpose of label smoothing in GAN training?",
      "options": [
        "To make labels more readable",
        "To reduce overconfidence in the discriminator",
        "To speed up training",
        "To reduce memory usage"
      ],
      "correctOptionIndex": 1,
      "explanation": "Label smoothing replaces hard labels (0 and 1) with soft labels (e.g., 0.1 and 0.9) to reduce discriminator overconfidence and provide better gradients to the generator.",
      "optionExplanations": [
        "Incorrect. Label smoothing is not about readability.",
        "Correct. Soft labels prevent the discriminator from becoming overconfident.",
        "Incorrect. Label smoothing doesn't directly affect training speed.",
        "Incorrect. Memory usage is not affected by label smoothing."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "label_smoothing",
        "soft_labels",
        "discriminator_confidence"
      ]
    },
    {
      "id": "GAN_087",
      "question": "What is instance noise in GAN training?",
      "options": [
        "Noise added to the generator input",
        "Noise added to real and fake samples before feeding to discriminator",
        "Noise in the training data",
        "Noise in the loss function"
      ],
      "correctOptionIndex": 1,
      "explanation": "Instance noise involves adding random noise to both real and generated samples before feeding them to the discriminator, helping to smooth the decision boundary and improve training stability.",
      "optionExplanations": [
        "Incorrect. Generator input noise is standard, not instance noise.",
        "Correct. Instance noise is added to samples before discriminator evaluation.",
        "Incorrect. This would be data noise, not instance noise.",
        "Incorrect. Instance noise is added to data, not the loss function."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "instance_noise",
        "training_stability",
        "decision_boundary"
      ]
    },
    {
      "id": "GAN_088",
      "question": "What is the mini-batch discrimination technique?",
      "options": [
        "Using smaller batch sizes",
        "Allowing the discriminator to look at multiple samples simultaneously",
        "Discriminating between mini-batches",
        "Training on random mini-batches"
      ],
      "correctOptionIndex": 1,
      "explanation": "Mini-batch discrimination allows the discriminator to examine multiple samples in a batch simultaneously to detect if the generator is producing similar samples, helping to address mode collapse.",
      "optionExplanations": [
        "Incorrect. It's not about batch size but about how samples are processed.",
        "Correct. The discriminator considers relationships between samples in a batch.",
        "Incorrect. It doesn't discriminate between different mini-batches.",
        "Incorrect. Random mini-batches are standard practice, not mini-batch discrimination."
      ],
      "difficulty": "HARD",
      "tags": [
        "mini_batch_discrimination",
        "mode_collapse",
        "batch_processing"
      ]
    },
    {
      "id": "GAN_089",
      "question": "What is the purpose of virtual batch normalization in GANs?",
      "options": [
        "To reduce memory usage",
        "To normalize batches that don't exist",
        "To reduce dependence between samples in a batch",
        "To speed up normalization"
      ],
      "correctOptionIndex": 2,
      "explanation": "Virtual batch normalization reduces the dependence between samples in a batch by normalizing each sample using statistics from a reference batch, improving training stability.",
      "optionExplanations": [
        "Incorrect. Virtual batch normalization doesn't primarily reduce memory usage.",
        "Incorrect. It uses a real reference batch for normalization.",
        "Correct. It reduces inter-sample dependencies within batches.",
        "Incorrect. Speed is not the primary goal of virtual batch normalization."
      ],
      "difficulty": "HARD",
      "tags": [
        "virtual_batch_normalization",
        "sample_independence",
        "training_stability"
      ]
    },
    {
      "id": "GAN_090",
      "question": "What is truncation trick in GANs?",
      "options": [
        "Truncating the network architecture",
        "Sampling from a truncated normal distribution",
        "Stopping training early",
        "Truncating generated images"
      ],
      "correctOptionIndex": 1,
      "explanation": "The truncation trick involves sampling noise from a truncated normal distribution (removing extreme values) to improve the quality of generated samples at the cost of some diversity.",
      "optionExplanations": [
        "Incorrect. Truncation trick affects sampling, not architecture.",
        "Correct. It uses truncated normal distribution for better quality samples.",
        "Incorrect. Early stopping is different from the truncation trick.",
        "Incorrect. It truncates the noise distribution, not the output images."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "truncation_trick",
        "sampling",
        "quality_diversity_tradeoff"
      ]
    },
    {
      "id": "GAN_091",
      "question": "What trade-off does the truncation trick create?",
      "options": [
        "Speed vs accuracy",
        "Memory vs computation",
        "Quality vs diversity",
        "Stability vs performance"
      ],
      "correctOptionIndex": 2,
      "explanation": "The truncation trick improves sample quality by avoiding extreme regions of the noise distribution, but this reduces diversity since fewer regions of the latent space are explored.",
      "optionExplanations": [
        "Incorrect. The truncation trick doesn't directly affect speed or accuracy.",
        "Incorrect. Memory and computation are not the primary trade-off.",
        "Correct. Better quality comes at the cost of reduced sample diversity.",
        "Incorrect. The trade-off is specifically between quality and diversity."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "truncation_trick",
        "quality_diversity_tradeoff",
        "sampling"
      ]
    },
    {
      "id": "GAN_092",
      "question": "What is orthogonal regularization in GANs?",
      "options": [
        "Using orthogonal activation functions",
        "Encouraging weight matrices to be orthogonal",
        "Using orthogonal data augmentation",
        "Orthogonal loss functions"
      ],
      "correctOptionIndex": 1,
      "explanation": "Orthogonal regularization adds a penalty term to encourage weight matrices to be orthogonal, which can improve training dynamics and help prevent mode collapse.",
      "optionExplanations": [
        "Incorrect. It's about weight matrices, not activation functions.",
        "Correct. It encourages orthogonality in network weight matrices.",
        "Incorrect. Data augmentation is not what orthogonal regularization refers to.",
        "Incorrect. Loss functions are not made orthogonal in this technique."
      ],
      "difficulty": "HARD",
      "tags": [
        "orthogonal_regularization",
        "weight_matrices",
        "training_dynamics"
      ]
    },
    {
      "id": "GAN_093",
      "question": "What is the main challenge when applying GANs to discrete data like text?",
      "options": [
        "Computational complexity",
        "Non-differentiable discrete sampling",
        "Memory requirements",
        "Training time"
      ],
      "correctOptionIndex": 1,
      "explanation": "The main challenge is that discrete sampling (like choosing words) is non-differentiable, making it difficult to backpropagate gradients through the generator for discrete outputs.",
      "optionExplanations": [
        "Incorrect. Computational complexity is not the primary issue.",
        "Correct. Discrete sampling breaks the gradient flow needed for training.",
        "Incorrect. Memory requirements are not the main challenge for discrete data.",
        "Incorrect. Training time is a secondary concern compared to the gradient flow problem."
      ],
      "difficulty": "HARD",
      "tags": [
        "discrete_data",
        "text_generation",
        "gradient_flow"
      ]
    },
    {
      "id": "GAN_094",
      "question": "What technique is commonly used to address the discrete sampling problem in GANs?",
      "options": [
        "Reinforcement learning approaches like REINFORCE",
        "Using different optimizers",
        "Increasing batch size",
        "Using residual connections"
      ],
      "correctOptionIndex": 0,
      "explanation": "Reinforcement learning techniques like REINFORCE or policy gradient methods are used to handle the non-differentiable discrete sampling in text generation GANs.",
      "optionExplanations": [
        "Correct. RL approaches can handle non-differentiable discrete actions.",
        "Incorrect. Different optimizers don't solve the discrete sampling problem.",
        "Incorrect. Batch size doesn't address the non-differentiability issue.",
        "Incorrect. Residual connections don't solve the discrete sampling problem."
      ],
      "difficulty": "HARD",
      "tags": [
        "discrete_sampling",
        "REINFORCE",
        "text_GANs"
      ]
    },
    {
      "id": "GAN_095",
      "question": "What is SeqGAN?",
      "options": [
        "A GAN for sequence prediction",
        "A GAN that uses reinforcement learning for text generation",
        "A GAN for sequential images",
        "A GAN with sequential training"
      ],
      "correctOptionIndex": 1,
      "explanation": "SeqGAN applies GANs to text generation by using reinforcement learning to handle the discrete nature of text, treating the generator as a policy that receives rewards from the discriminator.",
      "optionExplanations": [
        "Incorrect. While it handles sequences, the key innovation is the RL approach.",
        "Correct. SeqGAN uses RL to enable GAN training on discrete text data.",
        "Incorrect. SeqGAN is specifically for text, not sequential images.",
        "Incorrect. Sequential training is not what defines SeqGAN."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "SeqGAN",
        "text_generation",
        "reinforcement_learning"
      ]
    },
    {
      "id": "GAN_096",
      "question": "What is the main limitation of current GAN evaluation metrics like FID and IS?",
      "options": [
        "They are too slow to compute",
        "They may not fully capture human perception of quality",
        "They require too much memory",
        "They are only for image data"
      ],
      "correctOptionIndex": 1,
      "explanation": "Current metrics like FID and IS, while useful, may not fully align with human perception of image quality and can sometimes give misleading results about actual generation quality.",
      "optionExplanations": [
        "Incorrect. While they can be slow, this isn't the main limitation.",
        "Correct. These metrics may not perfectly correlate with human quality judgment.",
        "Incorrect. Memory usage is not the primary limitation.",
        "Incorrect. While mainly used for images, domain specificity isn't the main limitation."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "evaluation_metrics",
        "human_perception",
        "quality_assessment"
      ]
    },
    {
      "id": "GAN_097",
      "question": "What is the typical approach for handling different data modalities (like combining images and text) in GANs?",
      "options": [
        "Using separate GANs for each modality",
        "Multimodal GANs with shared or coupled architectures",
        "Converting all data to the same format",
        "Training sequentially on different modalities"
      ],
      "correctOptionIndex": 1,
      "explanation": "Multimodal GANs use architectures that can handle multiple data types simultaneously, often with shared components or coupling mechanisms to learn joint representations.",
      "optionExplanations": [
        "Incorrect. While possible, joint modeling is more effective for multimodal tasks.",
        "Correct. Multimodal GANs are designed to handle multiple data types together.",
        "Incorrect. Converting to the same format loses modality-specific information.",
        "Incorrect. Sequential training doesn't capture cross-modal relationships effectively."
      ],
      "difficulty": "HARD",
      "tags": [
        "multimodal_GANs",
        "data_modalities",
        "joint_representation"
      ]
    },
    {
      "id": "GAN_098",
      "question": "What is the significance of the theoretical contributions of GANs to machine learning?",
      "options": [
        "They only improved practical applications",
        "They introduced new concepts in game theory and generative modeling",
        "They simplified existing algorithms",
        "They reduced computational requirements"
      ],
      "correctOptionIndex": 1,
      "explanation": "GANs made significant theoretical contributions by connecting game theory with generative modeling and introducing new ways to think about learning distributions through adversarial processes.",
      "optionExplanations": [
        "Incorrect. GANs made both theoretical and practical contributions.",
        "Correct. GANs bridged game theory and generative modeling with novel theoretical insights.",
        "Incorrect. GANs introduced complexity rather than simplification.",
        "Incorrect. GANs typically increased computational requirements."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "theoretical_contributions",
        "game_theory",
        "generative_modeling"
      ]
    },
    {
      "id": "GAN_099",
      "question": "What is the current trend in GAN research as of recent years?",
      "options": [
        "Making GANs smaller and faster",
        "Improving training stability and controllability",
        "Reducing the number of parameters",
        "Simplifying architectures"
      ],
      "correctOptionIndex": 1,
      "explanation": "Current GAN research focuses heavily on improving training stability, achieving better controllability over generation, and developing more reliable training techniques.",
      "optionExplanations": [
        "Incorrect. While efficiency is important, stability and control are the main focus.",
        "Correct. Stability and controllability are major current research directions.",
        "Incorrect. Parameter reduction is not the primary current trend.",
        "Incorrect. Architectures are often becoming more complex, not simpler."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "research_trends",
        "training_stability",
        "controllability"
      ]
    },
    {
      "id": "GAN_100",
      "question": "What makes GANs particularly important in the broader context of artificial intelligence?",
      "options": [
        "They are the fastest generative models",
        "They demonstrate machines can create realistic content, advancing creative AI",
        "They use the least computational resources",
        "They are the easiest to implement"
      ],
      "correctOptionIndex": 1,
      "explanation": "GANs are significant because they demonstrate that machines can create highly realistic and creative content, representing a major milestone in AI's ability to generate rather than just analyze data.",
      "optionExplanations": [
        "Incorrect. Speed is not GANs' most important contribution to AI.",
        "Correct. GANs represent a breakthrough in machine creativity and content generation.",
        "Incorrect. GANs typically require significant computational resources.",
        "Incorrect. GANs are notoriously difficult to implement and train properly."
      ],
      "difficulty": "MEDIUM",
      "tags": [
        "AI_significance",
        "creative_AI",
        "content_generation"
      ]
    }
  ]
}